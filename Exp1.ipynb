{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPptAfb3Mpm0n7sXG1CGjHD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarithamiryala/DeepLearningLab/blob/main/Exp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Design and implement a neural based network for generating word embedding for words in a document corpus"
      ],
      "metadata": {
        "id": "j0I2GWcwTmEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense"
      ],
      "metadata": {
        "id": "ykyBj9yrTyrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlIvBWSEb5S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Prepare the Corpus\n",
        "corpus = [\n",
        "    \"Neural networks are a type of machine learning.\",\n",
        "    \"They are used for a variety of tasks like natural language processing.\",\n",
        "    \"Word embeddings represent words in continuous vector space.\"\n",
        "]"
      ],
      "metadata": {
        "id": "DBJqOLXxUlkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the corpus\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Pad sequences for uniform length\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Define the neural network\n",
        "embedding_dim = 8  # Dimensions of the embedding space\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "    Flatten(),\n",
        "    Dense(1, activation='sigmoid')  # Dummy output for illustration\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Dummy labels (binary classification for illustration)\n",
        "labels = np.array([0, 1, 0])\n",
        "\n",
        "# Train the model\n",
        "model.fit(padded_sequences, labels, epochs=10, verbose=1)\n",
        "\n",
        "# Extract word embeddings\n",
        "embeddings = model.layers[0].get_weights()[0]\n",
        "\n",
        "# Print word embeddings\n",
        "print(\"\\nWord Embeddings:\")\n",
        "for word, i in word_index.items():\n",
        "    print(f\"{word}: {embeddings[i]}\")"
      ],
      "metadata": {
        "id": "vtSG7urHUlpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6082d3-67f5-4699-cf84-12cda7a15642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6667 - loss: 0.6913\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.6844\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.6777\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6709\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6642\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6575\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.6509\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.6443\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6377\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6312\n",
            "\n",
            "Word Embeddings:\n",
            "are: [-0.01898655 -0.01515231 -0.00552111  0.00490055 -0.02352569  0.05454176\n",
            "  0.0392142   0.04677101]\n",
            "a: [-0.02423487 -0.00470717  0.0321662  -0.01951112  0.01826038 -0.01493653\n",
            "  0.0120742  -0.00548058]\n",
            "of: [ 1.0212208e-02 -5.5818940e-03 -6.8911992e-05  5.0498340e-02\n",
            " -1.8648146e-02  4.9004700e-02  3.3631891e-02 -1.8374158e-02]\n",
            "neural: [ 0.02225827  0.0029414   0.04435238  0.0329047  -0.01211275 -0.03764603\n",
            "  0.00636615 -0.03674182]\n",
            "networks: [-0.01778658  0.03525692 -0.01580917  0.00899153 -0.01178294  0.01555787\n",
            " -0.02054373 -0.03382109]\n",
            "type: [ 0.01020712  0.03921193 -0.05907817 -0.01905495  0.00042078 -0.03410821\n",
            "  0.00058458 -0.03000651]\n",
            "machine: [ 0.04191021  0.04376485 -0.00602616 -0.01968444  0.02884981 -0.02634536\n",
            "  0.0123884  -0.05490335]\n",
            "learning: [ 0.05125168 -0.0074229  -0.03242758  0.00949728 -0.0458043   0.03937278\n",
            "  0.03375552 -0.02955176]\n",
            "they: [ 0.00473037  0.01699189  0.01103323  0.05333242 -0.00016526 -0.02511457\n",
            "  0.0470627   0.03305998]\n",
            "used: [-0.0003061   0.01538724  0.01653799  0.02412345 -0.00759837 -0.02834849\n",
            " -0.00148501  0.01769026]\n",
            "for: [-0.01419808 -0.04791563 -0.02953182 -0.00583794  0.04124285 -0.02669681\n",
            "  0.01552372 -0.02527636]\n",
            "variety: [-0.01770144 -0.00673636 -0.02098278 -0.01492049  0.02250238  0.00722838\n",
            "  0.02088488  0.00878975]\n",
            "tasks: [ 0.00813945 -0.00040298 -0.00255334  0.01116327 -0.035911   -0.05613132\n",
            " -0.05385735  0.03851338]\n",
            "like: [-0.02912722  0.0296867  -0.05787545  0.02819262  0.00509794 -0.04506138\n",
            " -0.02111018 -0.02382241]\n",
            "natural: [-0.02894441 -0.00224523  0.00770343  0.02700995  0.00164517  0.00288639\n",
            "  0.00526951  0.0177451 ]\n",
            "language: [ 0.02891989  0.04507502  0.02790326 -0.03137569  0.01412033 -0.03768319\n",
            " -0.05414827 -0.016466  ]\n",
            "processing: [ 0.0164955  -0.03205767 -0.00884423 -0.03939892 -0.0468255  -0.0103807\n",
            "  0.01778413 -0.05920946]\n",
            "word: [ 0.0012236  -0.03364793  0.03918757  0.02052944  0.02690143 -0.0284416\n",
            "  0.03916955  0.02919866]\n",
            "embeddings: [-0.01306984  0.04192394 -0.00716176 -0.03818066  0.00722505 -0.00964987\n",
            "  0.00740867 -0.03773513]\n",
            "represent: [ 0.03596539  0.01691754  0.04691906  0.00162655  0.05664079 -0.02816429\n",
            " -0.01131892  0.02965573]\n",
            "words: [-0.02203179  0.04897025 -0.02479542 -0.00074547  0.01662934  0.03948743\n",
            "  0.00874579  0.04016499]\n",
            "in: [ 0.02434323 -0.03728867  0.03469504 -0.04803739 -0.05523981 -0.01149452\n",
            "  0.05266793 -0.03482395]\n",
            "continuous: [-0.03236087  0.0349317  -0.02068196  0.02876614 -0.03551758 -0.00758354\n",
            " -0.00024929  0.02826391]\n",
            "vector: [ 0.01365594 -0.00425701 -0.04296071  0.01706121  0.02155058 -0.03203312\n",
            "  0.01363254 -0.0351118 ]\n",
            "space: [ 0.01405959  0.00319377  0.03130386 -0.03624314 -0.02229396 -0.00051652\n",
            "  0.03434613  0.02757038]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vCerOmizUlsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3S5ezffXUlxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}